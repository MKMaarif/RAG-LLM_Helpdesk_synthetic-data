{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import faiss\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from llama_index.llms.groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_DB_PATH = \"../database/csv_database.db\"\n",
    "FAISS_INDEX_PATH = \"../database/faiss_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding function\n",
    "def get_embeddings():\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM model\n",
    "llm = Groq(model=\"llama-3.1-8b-instant\", api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Template\n",
    "PROMPT_TEMPLATE =\"\"\"\n",
    "    Jawab pertanyaan berdasarkan konteks dari PDF berikut: \n",
    "\n",
    "    {context}\n",
    "\n",
    "    ---\n",
    "\n",
    "    **Pertanyaan:**\n",
    "    {question}\n",
    "\n",
    "    ---\n",
    "    Hanya lanjutkan ke bagian di bawah ini jika benar-benar tidak ada informasi spesifik dalam konteks.\n",
    "    Jika pertanyaan yang diberikan terkait data riwayat penggunaan dan tidak ada informasi spesifik dalam konteks, jawablah dengan **SQL query** yang sesuai dengan contoh tabel berikut:\n",
    "\n",
    "    **Nama Tabel:** `synthetic_data`\n",
    "\n",
    "    **Contoh Data dalam Tabel (Format JSON, hanya contoh, tidak digunakan langsung dalam query):**\n",
    "    ```json\n",
    "    [\n",
    "        {{\"interaction_id\":1,\"user_id\":447,\"timestamp\":\"2024-03-12 17:56:48\",\"device_type\":\"Smart Speaker\",\"command_category\":\"Information\",\"command_text\":\"Apa rekomendasi restoran di sekitar sini?\",\"ai_response\":\"Akses ditolak\",\"response_time_ms\":310,\"ai_confidence_score\":67.97,\"user_satisfaction\":4,\"status\":\"Error\",\"error_code\":\"ERR403\"}},\n",
    "        {{\"interaction_id\":2,\"user_id\":469,\"timestamp\":\"2024-12-01 06:40:13\",\"device_type\":\"Smartphone\",\"command_category\":\"Productivity\",\"command_text\":\"Bagikan agenda meeting dengan anggota tim\",\"ai_response\":\"Tugas telah disimpan\",\"response_time_ms\":315,\"ai_confidence_score\":70.04,\"user_satisfaction\":5,\"status\":\"Success\",\"error_code\":null}}\n",
    "    ]\n",
    "    ```\n",
    "    Hanya jawab query SQL dalam bentuk string, tanpa memberi jawaban yang lain.\n",
    "\n",
    "    ---\n",
    "    Hanya jawab query SQL, jika tidak ada data yang sesuai dalam konteks.\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_DB = \"\"\"\n",
    "    Jawab pertanyaan berdasarkan hasil query SQL yang diberikan di bawah ini:\n",
    "    {sql_query_result}\n",
    "\n",
    "    ---\n",
    "    Jawab pertanyaan berikut:\n",
    "    {question}\n",
    "\n",
    "    Jawab tanpa menyebutkan penggunaan query SQL, tetapi parafrase pertanyaan untuk memberi jawaban yang natural.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_retrieval(question: str):\n",
    "    # Load embeddings & vector store\n",
    "    embeddings = get_embeddings()\n",
    "    vector_store = FAISS.load_local(FAISS_INDEX_PATH, embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "    # Search vector store\n",
    "    results = vector_store.similarity_search(question, k=5)\n",
    "    if not results:\n",
    "        return \"Maaf, saya tidak menemukan informasi yang relevan dalam dokumen.\"\n",
    "\n",
    "    context_text = '\\n\\n---\\n\\n'.join(doc.page_content for doc in results)\n",
    "\n",
    "    # Prepare prompt with clear formatting\n",
    "    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "    prompt = prompt_template.format(context=context_text, question=question)\n",
    "\n",
    "    # Generate response using LLM\n",
    "    response = llm.complete(prompt)\n",
    "    response = str(response)\n",
    "\n",
    "    # Validate if response contains an SQL query\n",
    "    if \"synthetic_data\" in response:  \n",
    "        # Take SQL query from response\n",
    "        response = response.split(\"```sql\")[1].strip()\n",
    "        response = response.split(\"```\")[0].strip()\n",
    "\n",
    "        try:\n",
    "            # Connect to SQLite database\n",
    "            conn = sqlite3.connect(SQL_DB_PATH)\n",
    "\n",
    "            # Execute SQL query safely\n",
    "            sql_query_result = pd.read_sql_query(response, conn)\n",
    "            conn.close()\n",
    "\n",
    "            # If DataFrame is empty, return error message\n",
    "            if sql_query_result.empty:\n",
    "                return \"Query berhasil dijalankan, tetapi tidak ada hasil yang ditemukan.\"\n",
    "\n",
    "            # Convert DataFrame to JSON format string\n",
    "            query_result_str = sql_query_result.to_json(orient=\"records\")\n",
    "\n",
    "            # Prepare second-stage prompt (SQL result â†’ natural language)\n",
    "            prompt_db = ChatPromptTemplate.from_template(PROMPT_DB)\n",
    "            final_prompt = prompt_db.format(sql_query_result=query_result_str, question=question)\n",
    "\n",
    "            # Generate final response\n",
    "            response = llm.complete (final_prompt)\n",
    "\n",
    "            return response\n",
    "        \n",
    "        except sqlite3.Error as e:\n",
    "            return f\"Terjadi kesalahan SQL: {e}\"\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object llm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict.<locals>.wrapped_gen at 0x0000027F28D06180>\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "question = 'Berapa rata-rata kepuasan pengguna AI Assistant X-3000 sebelumnya?'\n",
    "response = query_retrieval(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object llm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict.<locals>.wrapped_gen at 0x0000027F28D050E0>\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "question = 'Apa saja jenis perangkat yang digunakan oleh pengguna AI Assistant X-3000?'\n",
    "response = query_retrieval(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object llm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict.<locals>.wrapped_gen at 0x0000027F28D06180>\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "question = 'Apa teknologi yang digunakan untuk pengenalan wajah AI Assistant X-3000?'\n",
    "response = query_retrieval(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object llm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict.<locals>.wrapped_gen at 0x0000027F28D06180>\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "question = 'Apa fitur utama AI Assistant X-3000?'\n",
    "response = query_retrieval(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object llm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict.<locals>.wrapped_gen at 0x0000027F28D06180>\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "question = 'Bagaimana cara troubleshooting jika AI tidak merespons perintah suara?'\n",
    "response = query_retrieval(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object llm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict.<locals>.wrapped_gen at 0x0000027F28D06180>\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "question = 'Jelaskan cara menghubungkan AI Assistant X-3000 ke Wi-Fi.'\n",
    "response = query_retrieval(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
